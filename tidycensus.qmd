---
title: "tidycensus Exploration"
format: html
author: ElectriGrid
warning: false
message: false
---

This quarto document explores the Census ACS 5-year data utilizing the `tidycensus` package. The challenge is to narrow down the data from the 13,033 variables. The final output of this repository is a clean data frame to be utilized in the ElectriGrid MEDS capstone.


```{r}
# load necessary libraries
library(tidyverse)
library(tidycensus)
library(janitor)
```

# Census variable

Download a csv with the variables for the census data. 
```{r}
# access variable names to for selection of 
var20 <- load_variables(2020, "acs5", cache = TRUE)

#........................write data to csv.......................
write_csv(var20, file = here::here("census-data", "var20.csv")) 
```

There are slightly under 30,000 variables. 

#### Clean the labels 
Once the labels column is cleaned it can be utilized to filter down the variables. Here we keep only the numbers and letters. 
```{r}
var20_clean <- var20 |> 
  # clean label column
  mutate(label = str_replace_all(label, "[^A-Za-z0-9]", " ")) 
```

There is no argument for the level of variables when downloading the csv so we'll filter down to census tract. This is also specified when calling data but let's subset here to see the true number of variables change with future filtering.
```{r}
tract_var20 <- var20_clean |> filter(geography == "tract")
```

We only need some of the census data not all 13,000 rows. 

Subsetting for `Male` and `Female` below makes gives us 5,222 rows. This is too many variables and probably does not filter down to only the data we need. 
```{r}
# look at the number of variables for sex
sex <- c("Male", "Female")

# filter the variables by the variables of interest
tract_var20_sex <-  filter(tract_var20, 
                           str_detect(tract_var20$label, 
                                      paste(sex, collapse = "|")))
```
#### Subset based on key words of interest 

```{r}
# variables of interest
key_words <- c("Income", "Poverty", "Education", "Language", "Disability", "Employment", "Rent", "Family")

# filter the variables by the variables of interest
tract_var20_sub <-  filter(tract_var20, 
                           str_detect(tract_var20$label, 
                                      str_c("\\b(", str_c(key_words, collapse = "|"), ")\\b"))) # regex code for only exact matches

```
Subsetting for the key words in the labels column still gives 1,733 variables. 1,733 still seems like a ton of variables. 

#### Make a workflow

First lets attempt to get clean population data to create a workflow that can be used for all of the data. 
```{r}
white_pop <- sprintf("B01001A_0%02d", seq(1:31))
black_pop <- sprintf("B01001B_0%02d", seq(1:31))
native_pop <- sprintf("B01001C_0%02d", seq(1:31))
asian_pop <- sprintf("B01001D_0%02d", seq(1:31))
haw_pop <- sprintf("B01001E_0%02d", seq(1:31))
oth_rac_pop <- sprintf("B01001F_0%02d", seq(1:31))
rac2_pop <- sprintf("B01001G_0%02d", seq(1:31))
lat_pop <- sprintf("B01001I_0%02d", seq(1:31))

pop_var <- c(white_pop, black_pop, native_pop, asian_pop, haw_pop, oth_rac_pop, rac2_pop, lat_pop)
```

Since the `labels` will be used for the column names let's clean them. 
```{r}
var20_clean <- var20_clean |> 
   mutate(label = str_replace_all(label, " ", "_"))
```

The `concept` column also holds some pertinent data information. Let's clean them.
```{r}
var20_clean <- var20_clean |> 
   mutate(concept = str_replace_all(concept, " ", "_")) 
```

Since `labels` and `concepts` are both necessary to understand the data let's combine them.
```{r}
var20_clean$columns <- paste(var20_clean$label, var20_clean$concept)
```


Extract the column `columns` using the `name` column.
```{r}
 column_names <- var20_clean |> 
  filter(var20_clean$name %in% pop_var)
```

Access the data from the census catalogue. 
```{r}
# access census data
census_data <- get_acs(geography = "tract", 
                        variables = pop_var,
                        geometry = TRUE,
                        state = "CA", 
                        year = 2020)

```

Use the `column_names` to change the arbitrary `names` used to denote what the values actually mean.
```{r}
census_w_var <- census_data |> 
  left_join(column_names, by = c("variable" = "name"))
```

Select the columns that are needed for the analysis.

Note: moe stands for margin of error.
```{r}
clean_census<- census_w_var |> 
  clean_names() |> 
  select("geoid", "name", "estimate", "moe", "columns", "geometry") 
```

Pivot to make the data tidy. 
 There are two values for each variable. There are estimates and margins of error. These both get added as individual columns.
```{r}
pop_census_tidy <- clean_census |>
 pivot_wider(names_from = columns, values_from = c(estimate, moe)) |> 
  clean_names() 

#........................write data to csv.......................
write_csv(pop_census_tidy, file = here::here("census-data", "pop_census_tidy.csv"))  
```

# The clean data steps should be re-run once the variables list has been narrowed down
